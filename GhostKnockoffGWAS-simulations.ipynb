{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e77659e8",
   "metadata": {},
   "source": [
    "# Simulation studies using PAISA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0603520",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling CSV [336ed68f-0bac-5ca0-87d4-7b16caf5d00b]\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling DataFrames [a93c6f00-e57d-5684-b7b6-d8193f3e46c0]\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling DelimitedFiles [8bb1440f-4735-579b-a4ab-409b98df4dab]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "get_job_names (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "using DelimitedFiles\n",
    "\n",
    "# helper function to submit 1 job to run 1 command\n",
    "function submit(command::String, ncores::Int, total_mem::Number, \n",
    "        joblog_dir::String=\"/oak/stanford/groups/zihuai/paisa/slurms\"; \n",
    "        jobname=\"submit\", waitfor=Int[], verbose=true, highp=false)\n",
    "    mem = round(Int, total_mem / ncores) # memory per core\n",
    "    filename = \"$jobname.sh\"\n",
    "    open(filename, \"w\") do io\n",
    "        println(io, \"#!/bin/bash\")\n",
    "        println(io, \"#\")\n",
    "        println(io, \"#SBATCH --job-name=$jobname\")\n",
    "        println(io, \"#\")\n",
    "        if highp\n",
    "            println(io, \"#SBATCH --time=168:00:00\")\n",
    "        else\n",
    "            println(io, \"#SBATCH --time=24:00:00\")\n",
    "        end\n",
    "        println(io, \"#SBATCH --cpus-per-task=$ncores\")\n",
    "        println(io, \"#SBATCH --mem-per-cpu=$(mem)G\")\n",
    "        if highp\n",
    "            println(io, \"#SBATCH --partition=candes,zihuai\")\n",
    "        else\n",
    "            println(io, \"#SBATCH --partition=candes,zihuai,normal,owners\")\n",
    "        end\n",
    "        println(io, \"#SBATCH --output=$(joinpath(joblog_dir, \"slurm-%j.out\"))\")\n",
    "        println(io, \"\")\n",
    "        println(io, \"#save job info on joblog:\")\n",
    "        println(io, \"echo \\\"Job \\$JOB_ID started on:   \\\" `hostname -s`\")\n",
    "        println(io, \"echo \\\"Job \\$JOB_ID started on:   \\\" `date `\")\n",
    "        println(io, \"\")\n",
    "        println(io, \"# load the job environment:\")\n",
    "#         println(io, \"module load julia/1.9.4\")\n",
    "#         println(io, \"module load biology plink/1.90b5.3\")\n",
    "#         println(io, \"module load R/4.0.2\")\n",
    "#         println(io, \"export OPENBLAS_NUM_THREADS=1\")\n",
    "        println(io, \"export JULIA_DEPOT_PATH=\\\"/home/groups/sabatti/.julia\\\"\")\n",
    "        println(io, \"\")\n",
    "        println(io, \"# run code\")\n",
    "        println(io, \"echo \\\"$command\\\"\")\n",
    "        println(io, \"$command\")\n",
    "        println(io, \"\")\n",
    "        println(io, \"#echo job info on joblog:\")\n",
    "        println(io, \"echo \\\"Job \\$JOB_ID ended on:   \\\" `hostname -s`\")\n",
    "        println(io, \"echo \\\"Job \\$JOB_ID ended on:   \\\" `date `\")\n",
    "        println(io, \"#echo \\\" \\\"\")\n",
    "    end\n",
    "    # submit job and capture job ID\n",
    "    io = IOBuffer()\n",
    "    if length(waitfor) != 0\n",
    "        run(pipeline(`sbatch --dependency=afterok:$(join(waitfor, ':')) $filename`; stdout=io))\n",
    "    else\n",
    "        run(pipeline(`sbatch $filename`; stdout=io))\n",
    "    end\n",
    "    msg = String(take!(io))\n",
    "    verbose && print(stdout, msg)\n",
    "    jobid = parse(Int, strip(msg)[21:end])\n",
    "    # clean up and return job ID\n",
    "    close(io)\n",
    "    rm(filename, force=true)\n",
    "    return jobid\n",
    "end\n",
    "\n",
    "# helper function to submit 1 job to run multiple commands\n",
    "function submit(commands::Vector{String}, ncores::Int, total_mem::Number, \n",
    "        joblog_dir::String=\"/oak/stanford/groups/zihuai/paisa/slurms\"; \n",
    "        jobname=\"submit\", waitfor=Int[], verbose=true, highp=false)\n",
    "    mem = round(Int, total_mem / ncores) # memory per core\n",
    "    filename = \"$jobname.sh\"\n",
    "    open(filename, \"w\") do io\n",
    "        println(io, \"#!/bin/bash\")\n",
    "        println(io, \"#\")\n",
    "        println(io, \"#SBATCH --job-name=$jobname\")\n",
    "        println(io, \"#\")\n",
    "        if highp\n",
    "            println(io, \"#SBATCH --time=168:00:00\")\n",
    "        else\n",
    "            println(io, \"#SBATCH --time=24:00:00\")\n",
    "        end\n",
    "        println(io, \"#SBATCH --cpus-per-task=$ncores\")\n",
    "        println(io, \"#SBATCH --mem-per-cpu=$(mem)G\")\n",
    "        if highp\n",
    "            println(io, \"#SBATCH --partition=candes,zihuai\")\n",
    "        else\n",
    "            println(io, \"#SBATCH --partition=candes,zihuai,normal,owners\")\n",
    "        end\n",
    "        println(io, \"#SBATCH --output=$(joinpath(joblog_dir, \"slurm-%j.out\"))\")\n",
    "        println(io, \"\")\n",
    "        println(io, \"#save job info on joblog:\")\n",
    "        println(io, \"echo \\\"Job \\$JOB_ID started on:   \\\" `hostname -s`\")\n",
    "        println(io, \"echo \\\"Job \\$JOB_ID started on:   \\\" `date `\")\n",
    "        println(io, \"\")\n",
    "        println(io, \"# load the job environment:\")\n",
    "#         println(io, \"module load julia/1.9.4\")\n",
    "#         println(io, \"module load biology plink/1.90b5.3\")\n",
    "#         println(io, \"module load R/4.0.2\")\n",
    "#         println(io, \"export OPENBLAS_NUM_THREADS=1\")\n",
    "        println(io, \"export JULIA_DEPOT_PATH=\\\"/home/groups/sabatti/.julia\\\"\")\n",
    "        println(io, \"\")\n",
    "        for command in commands\n",
    "            println(io, \"echo \\\"$command\\\"\")\n",
    "            println(io, \"$command\")\n",
    "        end\n",
    "        println(io, \"\")\n",
    "        println(io, \"#echo job info on joblog:\")\n",
    "        println(io, \"echo \\\"Job \\$JOB_ID ended on:   \\\" `hostname -s`\")\n",
    "        println(io, \"echo \\\"Job \\$JOB_ID ended on:   \\\" `date `\")\n",
    "        println(io, \"#echo \\\" \\\"\")\n",
    "    end\n",
    "    # submit job and capture job ID\n",
    "    io = IOBuffer()\n",
    "    if length(waitfor) != 0\n",
    "        run(pipeline(`sbatch --dependency=afterok:$(join(waitfor, ':')) $filename`; stdout=io))\n",
    "    else\n",
    "        run(pipeline(`sbatch $filename`; stdout=io))\n",
    "    end\n",
    "    msg = String(take!(io))\n",
    "    verbose && print(stdout, msg)\n",
    "    jobid = parse(Int, strip(msg)[21:end])\n",
    "    # clean up and return job ID\n",
    "    close(io)\n",
    "    rm(filename, force=true)\n",
    "    return jobid\n",
    "end\n",
    "\n",
    "\n",
    "\"Run a Cmd object, returning the stdout & stderr contents plus the exit code\"\n",
    "function execute(cmd::Cmd)\n",
    "    out = Pipe()\n",
    "    err = Pipe()\n",
    "\n",
    "    process = run(pipeline(ignorestatus(cmd), stdout=out, stderr=err))\n",
    "    close(out.in)\n",
    "    close(err.in)\n",
    "\n",
    "    return (\n",
    "        stdout = String(read(out)), \n",
    "        stderr = String(read(err)),  \n",
    "        code = process.exitcode\n",
    "    )\n",
    "end\n",
    "\n",
    "function get_job_names()\n",
    "    data_str, _, _ = execute(`squeue -u bbchu -h -o \"%.30j\"`)\n",
    "    lines = split(data_str, \"\\n\")\n",
    "    jobnames = String[]\n",
    "    for line in lines\n",
    "        push!(jobnames, strip(line))\n",
    "    end\n",
    "    return jobnames\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3075038",
   "metadata": {},
   "source": [
    "## Run simulations\n",
    "\n",
    "This simulation: \n",
    "+ randomly chooses $k=50$ causal SNPs in chr21\n",
    "+ Z scores are formed by $z = X'y / sqrt(N)$\n",
    "+ marginal p-values computed by transforming Z-scores\n",
    "\n",
    "**This simulation doesn't quite work.** Knockoffs have power worse than marginal studies and FDR doesn't seem to be controlled, although the marginal false positive rate is much worse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dba596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put in script /oak/stanford/groups/zihuai/paisa/power_sim.jl\n",
    "\n",
    "using SnpArrays, Random, CSV, DataFrames, Distributions, StatsBase, GhostKnockoffGWAS\n",
    "include(\"/oak/stanford/groups/zihuai/paisa/utilities.jl\")\n",
    "\n",
    "seed = parse(Int, ARGS[1])\n",
    "LD_files = ARGS[2]\n",
    "datadir = ARGS[3] \n",
    "chr = parse(Int, ARGS[4])\n",
    "\n",
    "# for testing\n",
    "# seed = 1111 # computes shrinkage on all SNPs\n",
    "# seed = 1112 # computes shrinkage on reps\n",
    "# LD_files = \"/oak/stanford/groups/zihuai/paisa/LD_files_large2\"\n",
    "# datadir = \"/oak/stanford/groups/zihuai/paisa/GLIMPSE2_maf0.05\"\n",
    "# chr = 22\n",
    "\n",
    "# some helper functions\n",
    "function pval2zscore(pvals::AbstractVector{T}, beta::AbstractVector{T}) where T\n",
    "    length(pvals) == length(beta) || \n",
    "        error(\"pval2zscore: pvals and beta should have the same length\")\n",
    "    return zscore.(pvals, beta)\n",
    "end\n",
    "zscore(p::T, beta::T) where T = sign(beta) * quantile(Normal(), p/2)\n",
    "pval(z::T) where T = 2ccdf(Normal(), abs(z))\n",
    "\n",
    "# some unrealistic simulation parameters I made up just to check things works\n",
    "k = 50\n",
    "mu = 0\n",
    "sigma = 0.1 # beta ~ N(mu, sigma)\n",
    "\n",
    "# import genotypes\n",
    "xdata = SnpData(joinpath(datadir, \"chr$chr\"))\n",
    "X = SnpLinAlg{Float64}(xdata.snparray, center=true, scale=true, impute=true)\n",
    "n, p = size(X)\n",
    "\n",
    "# simulate phenotypes and normalize it\n",
    "Random.seed!(seed)\n",
    "beta = zeros(p)\n",
    "beta[1:k] .= rand(Normal(mu, sigma), k)\n",
    "shuffle!(beta)\n",
    "y = X * beta + randn(n)\n",
    "zscore!(y, mean(y), std(y))\n",
    "\n",
    "# marginal association test: Z scores and associated p-values\n",
    "z = X'*y ./ sqrt(n)\n",
    "pvals = pval.(z)\n",
    "\n",
    "# run GhostKnockoffGWAS on output of `solveblock`\n",
    "chrs = parse.(Int, xdata.snp_info.chromosome)\n",
    "pos = xdata.snp_info.position\n",
    "ref = xdata.snp_info.allele1\n",
    "alt = xdata.snp_info.allele2\n",
    "hg_build = 38\n",
    "outdir = \"/oak/stanford/groups/zihuai/paisa/sims\"\n",
    "outname = \"sim$seed\"\n",
    "total_time = @elapsed GhostKnockoffGWAS.ghostknockoffgwas(\n",
    "    LD_files, z, chrs, pos, Vector(ref), Vector(alt), n, hg_build, outdir,\n",
    "    outname = outname)\n",
    "\n",
    "# compute power\n",
    "outfile = joinpath(outdir, outname)\n",
    "snps = SNPs(xdata.snp_info.chromosome, pos, ref, alt)\n",
    "causal_snps = snps[findall(!iszero, beta)]\n",
    "GK_df = CSV.read(outfile * \".txt\", DataFrame)\n",
    "GK_snps = SNPs(string.(GK_df.chr), GK_df.pos_hg38, GK_df.ref, GK_df.alt)\n",
    "GK_df[!, \"true_beta\"] = zeros(size(GK_df, 1))\n",
    "idx1 = filter!(!isnothing, indexin(causal_snps, GK_snps))\n",
    "idx2 = filter!(!isnothing, indexin(causal_snps, snps))\n",
    "GK_df[idx1, \"true_beta\"] .= beta[idx2]\n",
    "GK_discover = findall(isone, GK_df[!, \"selected_fdr0.1\"])\n",
    "GK_snps = SNPs(string.(GK_df[!, \"chr\"]), GK_df[!, \"pos_hg38\"], GK_df[!, \"ref\"], GK_df[!, \"alt\"])\n",
    "GK_discover_snps = GK_snps[GK_discover]\n",
    "GK_power = length(intersect(GK_discover_snps, causal_snps)) / length(causal_snps)\n",
    "GK_FP = length(setdiff(GK_discover_snps, causal_snps))\n",
    "\n",
    "# marginal power (use pvalue from GK_df since some SNPs are deleted)\n",
    "# marginal_discover_snps = snps[findall(x -> x < 0.05/length(beta), pvals)]\n",
    "# marginal_power = length(intersect(marginal_discover_snps, causal_snps)) / length(causal_snps)\n",
    "# marginal_FP = length(setdiff(marginal_discover_snps, causal_snps))\n",
    "marginal_pvals = GK_df[!, \"pvals\"]\n",
    "marginal_discoveries = findall(x -> x < 0.05/size(GK_df, 1), marginal_pvals)\n",
    "true_beta_idx = findall(!iszero, GK_df[!, \"true_beta\"])\n",
    "marginal_power = length(intersect(marginal_discoveries, true_beta_idx)) / length(causal_snps)\n",
    "marginal_FP = length(setdiff(marginal_discoveries, true_beta_idx))\n",
    "println(\"\\n\\n marginal_power = $marginal_power, marginal false positives = $marginal_FP\")\n",
    "println(\"GK_power = $GK_power, GK false positives = $GK_FP\")\n",
    "println(\"Total GK time = $total_time\")\n",
    "\n",
    "# save GK_df with causal betas appended\n",
    "CSV.write(outfile * \".txt\", GK_df)\n",
    "\n",
    "# write output\n",
    "outfile = \"/oak/stanford/groups/zihuai/paisa/sims/sim$(seed)_result.txt\"\n",
    "open(outfile, \"w\") do io\n",
    "    println(io, \"GK_power,$GK_power\")\n",
    "    println(io, \"marginal_power,$marginal_power\")\n",
    "    println(io, \"GK_FP,$GK_FP\")\n",
    "    println(io, \"marginal_FP,$marginal_FP\")\n",
    "    println(io, \"total_time,$total_time\")\n",
    "end\n",
    "\n",
    "println(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d393ba",
   "metadata": {},
   "source": [
    "Submit jobs (MAF > 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad846737",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 51959063\n",
      "Submitted batch job 51959064\n",
      "Submitted batch job 51959065\n",
      "Submitted batch job 51959066\n",
      "Submitted batch job 51959067\n",
      "Submitted batch job 51959068\n",
      "Submitted batch job 51959069\n",
      "Submitted batch job 51959070\n",
      "Submitted batch job 51959071\n",
      "Submitted batch job 51959072\n"
     ]
    }
   ],
   "source": [
    "exe = \"/oak/stanford/groups/zihuai/paisa/power_sim.jl\"\n",
    "LD_files = \"/oak/stanford/groups/zihuai/paisa/LD_files\"\n",
    "datadir = \"/oak/stanford/groups/zihuai/paisa/GLIMPSE2_maf0.01\"\n",
    "chr = 21\n",
    "for sim in 1:10\n",
    "    submit(\"julia $exe $sim $LD_files $datadir $chr\", 1, 64, jobname=\"sim$sim\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452e16a6",
   "metadata": {},
   "source": [
    "## Simulation 2\n",
    "\n",
    "This simulation copies Zihuai's simulation:\n",
    "\n",
    "+ Simulation is run genome-wide\n",
    "+ Randomly choose $k$ regions\n",
    "+ Each region randomly pick 1 causal SNP\n",
    "\n",
    "```julia\n",
    "# merge PLINK files by chr if not done already\n",
    "# cd /oak/stanford/groups/zihuai/paisa/GLIMPSE2_maf0.05\n",
    "using SnpArrays\n",
    "prefix = \"chr\"\n",
    "merge_plink(prefix; des = \"allchr\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b66f56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put in script /oak/stanford/groups/zihuai/paisa/power_sim.jl\n",
    "\n",
    "using SnpArrays, Random, CSV, DataFrames, Distributions, StatsBase, GhostKnockoffGWAS\n",
    "include(\"/oak/stanford/groups/zihuai/paisa/utilities.jl\")\n",
    "\n",
    "seed = parse(Int, ARGS[1])\n",
    "LD_files = ARGS[2]\n",
    "datadir = ARGS[3] \n",
    "\n",
    "# for testing\n",
    "# seed = 1111\n",
    "# LD_files = \"/oak/stanford/groups/zihuai/paisa/LD_files\"\n",
    "# datadir = \"/oak/stanford/groups/zihuai/paisa/GLIMPSE2_maf0.01\"\n",
    "\n",
    "# some helper functions\n",
    "function pval2zscore(pvals::AbstractVector{T}, beta::AbstractVector{T}) where T\n",
    "    length(pvals) == length(beta) || \n",
    "        error(\"pval2zscore: pvals and beta should have the same length\")\n",
    "    return zscore.(pvals, beta)\n",
    "end\n",
    "zscore(p::T, beta::T) where T = sign(beta) * quantile(Normal(), p/2)\n",
    "pval(z::T) where T = 2ccdf(Normal(), abs(z))\n",
    "\n",
    "# simulation parameters\n",
    "k = 50\n",
    "\n",
    "# import genotypes\n",
    "xdata = SnpData(joinpath(datadir, \"allchr\"))\n",
    "X = SnpLinAlg{Float64}(xdata.snparray, center=true, scale=true, impute=true)\n",
    "n, p = size(xdata)\n",
    "\n",
    "# randomly pick k regions to have 1 causal SNP\n",
    "Random.seed!(seed)\n",
    "beta = zeros(p)\n",
    "regions_df = CSV.read(joinpath(LD_files, \"all_regions.txt\"), DataFrame)\n",
    "causal_regions = sample(1:size(regions_df, 1), k, replace=false)\n",
    "for i in causal_regions\n",
    "    try\n",
    "        chr, start_pos, end_pos = regions_df[i, :]\n",
    "        info_file = joinpath(LD_files, \"chr$chr\", \"Info_start$(start_pos)_end$(end_pos).csv\")\n",
    "        info = CSV.read(info_file, DataFrame)\n",
    "        pi = size(info, 1)\n",
    "        _, AF, causal_chr, causal_pos, causal_ref, causal_alt = info[sample(1:pi), :]\n",
    "        MAF = AF > 0.5 ? 1 - AF : AF\n",
    "        idx = findfirst(x -> \n",
    "            x.chromosome == string(causal_chr) && \n",
    "            x.position == causal_pos && \n",
    "            x.allele1 == causal_ref && \n",
    "            x.allele2 == causal_alt, \n",
    "            eachrow(xdata.snp_info)\n",
    "        )\n",
    "        beta[idx] = 1 / sqrt(2MAF * (1 - MAF))\n",
    "    catch\n",
    "        continue\n",
    "    end\n",
    "end\n",
    "\n",
    "# simulate phenotypes and normalize it\n",
    "Random.seed!(seed)\n",
    "y = X * beta + rand(Normal(0, sqrt(3)), n) # ~100 sec\n",
    "zscore!(y, mean(y), std(y))\n",
    "\n",
    "# marginal association test: Z scores and associated p-values\n",
    "z = X'*y ./ sqrt(n)\n",
    "pvals = pval.(z)\n",
    "\n",
    "# run GhostKnockoffGWAS on output of `solveblock`\n",
    "chrs = parse.(Int, xdata.snp_info.chromosome)\n",
    "pos = xdata.snp_info.position\n",
    "ref = xdata.snp_info.allele1\n",
    "alt = xdata.snp_info.allele2\n",
    "hg_build = 38\n",
    "outdir = \"/oak/stanford/groups/zihuai/paisa/sims\"\n",
    "outname = \"sim$seed\"\n",
    "total_time = @elapsed GhostKnockoffGWAS.ghostknockoffgwas(\n",
    "    LD_files, z, chrs, pos, Vector(ref), Vector(alt), n, hg_build, outdir,\n",
    "    outname = outname)\n",
    "\n",
    "# compute power\n",
    "outfile = joinpath(outdir, outname)\n",
    "snps = SNPs(xdata.snp_info.chromosome, pos, ref, alt)\n",
    "causal_snps = snps[findall(!iszero, beta)]\n",
    "GK_df = CSV.read(outfile * \".txt\", DataFrame)\n",
    "GK_snps = SNPs(string.(GK_df.chr), GK_df.pos_hg38, GK_df.ref, GK_df.alt)\n",
    "GK_df[!, \"true_beta\"] = zeros(size(GK_df, 1))\n",
    "idx1 = filter!(!isnothing, indexin(causal_snps, GK_snps))\n",
    "idx2 = filter!(!isnothing, indexin(causal_snps, snps))\n",
    "GK_df[idx1, \"true_beta\"] .= beta[idx2]\n",
    "GK_discover = findall(isone, GK_df[!, \"selected_fdr0.1\"])\n",
    "GK_snps = SNPs(string.(GK_df[!, \"chr\"]), GK_df[!, \"pos_hg38\"], GK_df[!, \"ref\"], GK_df[!, \"alt\"])\n",
    "GK_discover_snps = GK_snps[GK_discover]\n",
    "GK_power = length(intersect(GK_discover_snps, causal_snps)) / length(causal_snps)\n",
    "GK_FP = length(setdiff(GK_discover_snps, causal_snps))\n",
    "\n",
    "# marginal power (use pvalue from GK_df since some SNPs are deleted)\n",
    "# marginal_discover_snps = snps[findall(x -> x < 0.05/length(beta), pvals)]\n",
    "# marginal_power = length(intersect(marginal_discover_snps, causal_snps)) / length(causal_snps)\n",
    "# marginal_FP = length(setdiff(marginal_discover_snps, causal_snps))\n",
    "marginal_pvals = GK_df[!, \"pvals\"]\n",
    "marginal_discoveries = findall(x -> x < 5e-8, marginal_pvals)\n",
    "true_beta_idx = findall(!iszero, GK_df[!, \"true_beta\"])\n",
    "marginal_power = length(intersect(marginal_discoveries, true_beta_idx)) / length(causal_snps)\n",
    "marginal_FP = length(setdiff(marginal_discoveries, true_beta_idx))\n",
    "println(\"\\n\\n marginal_power = $marginal_power, marginal false positives = $marginal_FP\")\n",
    "println(\"GK_power = $GK_power, GK false positives = $GK_FP\")\n",
    "println(\"Total GK time = $total_time\")\n",
    "\n",
    "# save GK_df with causal betas appended\n",
    "CSV.write(outfile * \".txt\", GK_df)\n",
    "\n",
    "# write output\n",
    "outfile = \"/oak/stanford/groups/zihuai/paisa/sims/sim$(seed)_result.txt\"\n",
    "open(outfile, \"w\") do io\n",
    "    println(io, \"GK_power,$GK_power\")\n",
    "    println(io, \"marginal_power,$marginal_power\")\n",
    "    println(io, \"GK_FP,$GK_FP\")\n",
    "    println(io, \"marginal_FP,$marginal_FP\")\n",
    "    println(io, \"total_time,$total_time\")\n",
    "end\n",
    "\n",
    "println(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6944254",
   "metadata": {},
   "source": [
    "Note: `solveblock` was compiled with `julia/1.9.0` but on Sep 10, 2024 `module load julia/1.9.0` stopped working. We either invoke julia/1.9.0 directly or we must recompile the executable (and re-solve all regions using whatever version of Julia) using the latest julia version. If we recompile, we need to check the executable can read the `EUR` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ee6dde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 52937525\n",
      "Submitted batch job 52937575\n",
      "Submitted batch job 52937576\n",
      "Submitted batch job 52937577\n",
      "Submitted batch job 52937578\n",
      "Submitted batch job 52937579\n",
      "Submitted batch job 52937580\n",
      "Submitted batch job 52937581\n",
      "Submitted batch job 52937582\n",
      "Submitted batch job 52937583\n"
     ]
    }
   ],
   "source": [
    "julia = \"/share/software/user/open/julia/1.9.0/bin/julia\" \n",
    "exe = \"/oak/stanford/groups/zihuai/paisa/power_sim.jl\"\n",
    "LD_files = \"/oak/stanford/groups/zihuai/paisa/LD_files_maf0.05\"\n",
    "datadir = \"/oak/stanford/groups/zihuai/paisa/GLIMPSE2_maf0.05\"\n",
    "for sim in 11:20\n",
    "    submit(\"$julia $exe $sim $LD_files $datadir\", 1, 250, jobname=\"sim$sim\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b18d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
